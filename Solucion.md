# Soluci√≥n propuesta para replicaci√≥n de datos de SQL Server a BigQuery

En este documento se presenta la soluci√≥n propuesta para la replicaci√≥n de datos de SQL Server a BigQuery

## Arquitectura

Este es el diagrama de arquitectura que nos permite entender como podemos realizar replicaci√≥n de tablas desde SQL Server hacia BigQuery en GCP.

![Arquitectura Carga Inicial](/images/Arquitectura_Inicial.jpg)
_Diagrama 1. Arquitectura de la carga inicial de datos_      


![Arquitectura Carga Inicial](/images/Arquitectura_Replicacion.jpg)
_Diagrama 2. Arquitectura de la replicaci√≥n de datos_       


### Supuestos üìã
En esta soluci√≥n propuesta se asume que existe comunicaci√≥n entre la nube de GCP y los servidores de SQL Server, por lo cual los scripts y c√≥digos mostrados en este repositorio no contemplan alguna configuraci√≥n de redes.

### Pre-requisitos üìã

1. Habilitar el CDC en SQL Server tanto en la Base de Datos como en las tablas:
```
-- enable CDC on the database
EXEC sys.sp_cdc_enable_db;
-- enable CDC on the CatLineasAereas table
EXEC sys.sp_cdc_enable_table
  @source_schema = N'dbo',
  @source_name   = N'CatLineasAereas',
  @role_name     = NULL;
-- enable CDC on the Pasajeros table
EXEC sys.sp_cdc_enable_table
  @source_schema = N'dbo',
  @source_name   = N'Pasajeros',
  @role_name     = NULL;
-- enable CDC on the Vuelos table
EXEC sys.sp_cdc_enable_table
  @source_schema = N'dbo',
  @source_name   = N'Vuelos',
  @role_name     = NULL;
```
   
2. Crear los datasets y las tablas necesarias en BigQuery
Creaci√≥n de datasets
```
-- create dataset central
CREATE SCHEMA central
OPTIONS(
  location="us"
  );
-- create dataset sucursal1
CREATE SCHEMA sucursal1
OPTIONS(
  location="us"
  );
-- create dataset sucursal2
CREATE SCHEMA sucursal2
OPTIONS(
  location="us"
  );
```

Creaci√≥n de tablas
```
-- create table CatLineasAereas
CREATE TABLE central.CatLineasAereas
(
  code STRING,
  linea_aerea STRING
);
-- create table sucursal1.Pasajeros 
CREATE TABLE sucursal1.Pasajeros
(
  id_pasajero INT64,
  pasajero STRING,
  edad INT64
);
-- create table sucursal1.Vuelos
CREATE TABLE sucursal1.Vuelos
(
  cve_la STRING,
  viaje DATE,
  clase STRING,
  precio NUMERIC,
  Ruta STRING,
  cve_cliente INT64
);
-- create table sucursal2.Pasajeros 
CREATE TABLE sucursal2.Pasajeros
(
  id_pasajero INT64,
  pasajero STRING,
  edad INT64
);
-- create table sucursal2.Vuelos
CREATE TABLE sucursal2.Vuelos
(
  cve_la STRING,
  viaje DATE,
  clase STRING,
  precio NUMERIC,
  Ruta STRING,
  cve_cliente INT64
);
```

## Soluci√≥n üîß
* El diagrama 1 muestra la arquitectura para realizar la carga inicial de las tablas originales que se encuentran en SQL Server.
    - Se debe ejecutar un job en el servicio de Dataproc Serverless, este job lanzar√° un ETL el cual est√° codificado en c√≥digo PySpark y su nombre es [load_init.py](/dataproc/load_init.py)
* Invita una cerveza üç∫ o un caf√© ‚òï a alguien del equipo. 
* Da las gracias p√∫blicamente ü§ì.
* Dona con cripto a esta direcci√≥n: `0xf253fc233333078436d111175e5a76a649890000`
* etc.

## Autor ‚úíÔ∏è

* **Genaro Z√°rate** - *Documentaci√≥n* - [gzarate71](https://github.com/gzarate71)

